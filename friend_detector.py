import cv2
import numpy as np
import face_recognition
from PIL import Image, ImageEnhance, ImageDraw, ImageFont
import pickle
import os
import time
import threading
import pyautogui

# è¨­å®šåƒæ•¸
FRIEND_NAME = "Your Friend"
CONFIDENCE_THRESHOLD = 0.37
TRIGGER_DISTANCE = 180
ENCODINGS_FILE = "known_face_encodings.pkl"
VIDEO_PATH = "update.mp4"  # ç¢ºä¿é€™å€‹æª”æ¡ˆå­˜åœ¨
NO_FRIEND_FRAMES_THRESHOLD = 15

# ä¸­æ–‡æ–‡å­—ç¹ªè£½å‡½æ•¸
def cv2_puttext_chinese(img, text, position, font_size, color):
    """åœ¨OpenCVåœ–åƒä¸Šç¹ªè£½ä¸­æ–‡æ–‡å­—"""
    img_pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    draw = ImageDraw.Draw(img_pil)
    
    try:
        font = ImageFont.truetype("msyh.ttc", font_size)  # Windows å¾®è»Ÿé›…é»‘
    except:
        try:
            font = ImageFont.truetype("arial.ttf", font_size)  # å‚™ç”¨å­—é«”
        except:
            font = ImageFont.load_default()
    
    draw.text(position, text, font=font, fill=color)
    return cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)

# å½±ç‰‡æ’­æ”¾å™¨é¡
class VideoPlayer:
    def __init__(self, video_path):
        self.video_path = video_path
        self.is_playing = False
        self.window_name = "Video Player"
        self.thread = None
        
        # æª¢æŸ¥å½±ç‰‡æª”æ¡ˆæ˜¯å¦å­˜åœ¨
        if not os.path.exists(video_path):
            print(f"è­¦å‘Š: å½±ç‰‡æª”æ¡ˆä¸å­˜åœ¨: {video_path}")
            self.video_exists = False
        else:
            self.video_exists = True
            self.cap = cv2.VideoCapture(video_path)
    
    def play(self):
        if not self.video_exists:
            print("ç„¡æ³•æ’­æ”¾å½±ç‰‡ï¼šæª”æ¡ˆä¸å­˜åœ¨")
            return
            
        if not self.is_playing:
            self.is_playing = True
            self.thread = threading.Thread(target=self._play_loop)
            self.thread.daemon = True
            self.thread.start()

    def stop(self):
        self.is_playing = False
        if self.thread and self.thread.is_alive():
            self.thread.join(timeout=1)
        try:
            cv2.destroyWindow(self.window_name)
        except:
            pass
    
    def _play_loop(self):
        if not self.video_exists:
            return
            
        try:
            while self.is_playing:
                self.cap.set(cv2.CAP_PROP_POS_FRAMES, 0)  # é‡ç½®åˆ°é–‹é ­
                
                while self.is_playing:
                    ret, frame = self.cap.read()
                    if not ret:
                        break
                    
                    # ç²å–è¢å¹•å°ºå¯¸ä¸¦èª¿æ•´å½±ç‰‡å¤§å°
                    try:
                        screen_width, screen_height = pyautogui.size()
                        frame = cv2.resize(frame, (screen_width, screen_height))
                    except:
                        # å¦‚æœç„¡æ³•ç²å–è¢å¹•å°ºå¯¸ï¼Œä½¿ç”¨é è¨­å¤§å°
                        frame = cv2.resize(frame, (1280, 720))
                    
                    # å‰µå»ºå…¨è¢å¹•è¦–çª—
                    cv2.namedWindow(self.window_name, cv2.WINDOW_NORMAL)
                    cv2.setWindowProperty(self.window_name, cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)
                    
                    cv2.imshow(self.window_name, frame)
                    
                    # æª¢æŸ¥æŒ‰éµ
                    key = cv2.waitKey(30) & 0xFF
                    if key == 27:  # ESCéµ
                        self.is_playing = False
                        break
                        
        except Exception as e:
            print(f"å½±ç‰‡æ’­æ”¾éŒ¯èª¤: {e}")
        finally:
            try:
                cv2.destroyWindow(self.window_name)
            except:
                pass

def preprocess_image(image_path):
    """é è™•ç†åœ–ç‰‡ä»¥æé«˜äººè‡‰æª¢æ¸¬æˆåŠŸç‡"""
    try:
        pil_image = Image.open(image_path)
        
        if pil_image.mode != 'RGB':
            pil_image = pil_image.convert('RGB')
        
        # èª¿æ•´äº®åº¦å’Œå°æ¯”åº¦
        enhancer = ImageEnhance.Brightness(pil_image)
        pil_image = enhancer.enhance(1.2)
        
        enhancer = ImageEnhance.Contrast(pil_image)
        pil_image = enhancer.enhance(1.1)
        
        image_array = np.array(pil_image)
        return image_array
        
    except Exception as e:
        print(f"é è™•ç†åœ–ç‰‡ {image_path} å¤±æ•—: {str(e)}")
        return None

def load_or_create_encodings(image_paths):
    """è¼‰å…¥æˆ–å‰µå»ºäººè‡‰ç·¨ç¢¼"""
    if os.path.exists(ENCODINGS_FILE):
        try:
            with open(ENCODINGS_FILE, "rb") as f:
                print("å¾æ–‡ä»¶åŠ è¼‰é è¨ˆç®—çš„è‡‰éƒ¨ç‰¹å¾µ...")
                return pickle.load(f)
        except Exception as e:
            print(f"è¼‰å…¥ç·¨ç¢¼æª”æ¡ˆå¤±æ•—: {e}")
            print("é‡æ–°è¨ˆç®—è‡‰éƒ¨ç‰¹å¾µ...")

    print("è¨ˆç®—è‡‰éƒ¨ç‰¹å¾µä¸­...")
    known_encodings = []
    valid_images = 0
    failed_images = []

    for i, path in enumerate(image_paths):
        print(f"è™•ç†é€²åº¦: {i+1}/{len(image_paths)} - {os.path.basename(path)}")
        
        try:
            if not os.path.exists(path):
                print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {path}")
                failed_images.append(path)
                continue
            
            # é è™•ç†åœ–ç‰‡
            image = preprocess_image(path)
            if image is None:
                failed_images.append(path)
                continue
            
            # æª¢æ¸¬äººè‡‰
            face_locations = face_recognition.face_locations(image, model="hog")
            
            if not face_locations:
                print(f"âŒ æœªæª¢æ¸¬åˆ°äººè‡‰")
                failed_images.append(path)
                continue

            # é¸æ“‡æœ€å¤§çš„äººè‡‰
            if len(face_locations) > 1:
                largest_face = max(face_locations, 
                                 key=lambda loc: (loc[2] - loc[0]) * (loc[1] - loc[3]))
                face_locations = [largest_face]

            # æå–ç‰¹å¾µç·¨ç¢¼
            encodings = face_recognition.face_encodings(image, known_face_locations=face_locations)
            
            if encodings:
                known_encodings.append(encodings[0])
                valid_images += 1
                print(f"âœ… æˆåŠŸæå–ç‰¹å¾µ")
            else:
                print(f"âŒ ç‰¹å¾µæå–å¤±æ•—")
                failed_images.append(path)
                
        except Exception as e:
            print(f"âŒ è™•ç†éŒ¯èª¤: {str(e)}")
            failed_images.append(path)

    # çµæœçµ±è¨ˆ
    print(f"\n{'='*50}")
    print(f"è™•ç†å®Œæˆçµ±è¨ˆ:")
    print(f"ç¸½åœ–ç‰‡æ•¸: {len(image_paths)}")
    print(f"æˆåŠŸè™•ç†: {valid_images}")
    print(f"å¤±æ•—æ•¸é‡: {len(failed_images)}")
    print(f"æˆåŠŸç‡: {valid_images/len(image_paths)*100:.1f}%")

    if valid_images >= 3:
        try:
            with open(ENCODINGS_FILE, "wb") as f:
                pickle.dump(known_encodings, f)
            print(f"\nâœ… ç‰¹å¾µç·¨ç¢¼å·²ä¿å­˜åˆ° {ENCODINGS_FILE}")
        except Exception as e:
            print(f"ä¿å­˜ç·¨ç¢¼æª”æ¡ˆå¤±æ•—: {e}")
    else:
        print(f"\nâŒ éŒ¯èª¤: åªæœ‰ {valid_images} å¼µæœ‰æ•ˆç…§ç‰‡ï¼Œè‡³å°‘éœ€è¦3å¼µ")

    return known_encodings

def main():
    """ä¸»ç¨‹å¼"""
    # åœ–ç‰‡è·¯å¾‘åˆ—è¡¨
    image_paths = [
        "02/03 (1).jpg",
        "02/03 (2).jpg",
        "02/03 (3).jpg",
        "02/03 (4).jpg",
        "02/03 (5).jpg",
        "02/03 (6).jpg",
        "02/03 (7).jpg",
        "02/03 (8).jpg",
        "02/03 (9).jpg",
        "02/03 (10).jpg",
        "02/03 (11).jpg",
        "02/03 (12).jpg",
        "02/03 (13).jpg",
        "02/03 (14).jpg",
        "02/03 (15).jpg",
        "02/03 (16).jpg",
        "02/03 (17).jpg",
        "02/03 (18).jpg",
        "02/03 (19).jpg",
        "02/03 (20).jpg",
        "02/03 (21).jpg",
        "02/03 (22).jpg",
        "02/03 (23).jpg",
        "02/03 (24).jpg",
        "02/03 (25).jpg",
        "02/03 (26).jpg",
        "02/03 (27).jpg",
        "02/03 (28).jpg",
        "02/03 (29).jpg",
        "02/03 (30).jpg",
        "02/03 (31).jpg",
        "02/03 (32).jpg",
        "02/03 (33).jpg",
        "02/03 (34).jpg",
        "02/03 (35).jpg",
        "02/03 (36).jpg",
        "02/03 (37).jpg",
        "02/03 (38).jpg",
        "02/03 (39).jpg",
        "02/03 (40).jpg",
        "02/03 (41).jpg",
        "02/03 (42).jpg",
        "02/03 (43).jpg",
        "02/03 (44).jpg",
        "02/03 (45).jpg",
        "02/03 (46).jpg",
        "02/03 (47).jpg",
        "02/03 (48).jpg",
        "02/03 (49).jpg",
        "02/03 (50).jpg",
        "02/03 (51).jpg",
        "02/03 (52).jpg",
        "02/03 (53).jpg",
        "02/03 (54).jpg",
        "02/03 (55).jpg",
        "02/03 (56).jpg",
        "02/03 (57).jpg",
        "02/03 (58).jpg",
        "02/03 (59).jpg",
        "02/03 (60).jpg",
        "02/03 (61).jpg",
        "02/03 (62).jpg",
        "02/03 (63).jpg",
        "02/03 (64).jpg",
        "02/03 (65).jpg",
        "02/03 (66).jpg",
        
        "02/01 (1).png",
        "02/01 (2).png",
        "02/01 (3).png",
        "02/01 (4).png",
        "02/01 (5).png",
        "02/01 (6).png",
        "02/01 (7).png",
        "02/01 (8).png",
        "02/01 (9).png",
        "02/01 (10).png",
        "02/01 (11).png",
        "02/01 (12).png",
        "02/01 (13).png",
        "02/01 (14).png",
        "02/01 (15).png",
        "02/01 (16).png",
        "02/01 (17).png",
        "02/01 (18).png",
        "02/01 (19).png",
        "02/01 (20).png",
        "02/01 (21).png",
        "02/01 (22).png",
        "02/01 (23).png",
        "02/01 (24).png",
        "02/01 (25).png",
        "02/01 (26).png",
        "02/01 (27).png",  
    ]
    
    # è¼‰å…¥äººè‡‰ç·¨ç¢¼
    print("æ­£åœ¨åˆå§‹åŒ–è‡‰éƒ¨ç‰¹å¾µæ•¸æ“šåº«...")
    known_face_encodings = load_or_create_encodings(image_paths)
    
    if not known_face_encodings or len(known_face_encodings) < 3:
        print("éŒ¯èª¤: éœ€è¦è‡³å°‘3å¼µæœ‰æ•ˆæœ‹å‹ç…§ç‰‡æ‰èƒ½é‹è¡Œï¼")
        print("è«‹æª¢æŸ¥:")
        print("1. åœ–ç‰‡è·¯å¾‘æ˜¯å¦æ­£ç¢º")
        print("2. åœ–ç‰‡ä¸­æ˜¯å¦æœ‰æ¸…æ¥šçš„äººè‡‰")
        print("3. åœ–ç‰‡æ ¼å¼æ˜¯å¦æ”¯æ´")
        return

    # åˆå§‹åŒ–å½±ç‰‡æ’­æ”¾å™¨
    video_player = VideoPlayer(VIDEO_PATH)
    
    # åˆå§‹åŒ–æ”å½±æ©Ÿ
    print("åˆå§‹åŒ–æ”å½±æ©Ÿ...")
    cap = cv2.VideoCapture(0)
    
    if not cap.isOpened():
        print("éŒ¯èª¤ï¼šç„¡æ³•é–‹å•Ÿæ”å½±æ©Ÿï¼")
        print("è«‹æª¢æŸ¥:")
        print("1. æ”å½±æ©Ÿæ˜¯å¦é€£æ¥")
        print("2. æ˜¯å¦æœ‰å…¶ä»–ç¨‹å¼æ­£åœ¨ä½¿ç”¨æ”å½±æ©Ÿ")
        print("3. æ”å½±æ©Ÿé©…å‹•æ˜¯å¦æ­£å¸¸")
        return

    # è¨­å®šæ”å½±æ©Ÿè§£æåº¦
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

    # ä¸»è¦æª¢æ¸¬å¾ªç’°
    print("ğŸš€ æœ‹å‹æª¢æ¸¬ç³»çµ±å•Ÿå‹•ä¸­...")
    print("æŒ‰ 'q' é€€å‡º")
    print("å½±ç‰‡æ’­æ”¾æ™‚æŒ‰ ESC å¯é—œé–‰å½±ç‰‡")
    
    friend_detected = False
    frame_count = 0
    no_friend_frames = 0
    fps_start_time = time.time()
    DETECTION_INTERVAL = 3

    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                print("ç„¡æ³•è®€å–æ”å½±æ©Ÿç•«é¢")
                time.sleep(0.1)
                continue

            frame_count += 1
            current_time = time.time()

            # æª¢æ¸¬é‚è¼¯
            if friend_detected:
                do_detection = (frame_count % 2 == 0)
            else:
                do_detection = (frame_count % DETECTION_INTERVAL == 0)

            if do_detection:
                # ç¸®å°å¹€ä»¥æé«˜è™•ç†é€Ÿåº¦
                small_frame = cv2.resize(frame, (0, 0), fx=0.5, fy=0.5)
                rgb_small_frame = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)
                
                # æª¢æ¸¬äººè‡‰
                face_locations = face_recognition.face_locations(rgb_small_frame, model="hog")
                
                friend_found_this_frame = False
                
                if face_locations:
                    # è½‰æ›åº§æ¨™åˆ°åŸå§‹å°ºå¯¸
                    face_locations = [(int(top * 2), int(right * 2), int(bottom * 2), int(left * 2))
                                    for (top, right, bottom, left) in face_locations]
                    
                    # ç²å–äººè‡‰ç·¨ç¢¼
                    face_encodings = face_recognition.face_encodings(
                        cv2.cvtColor(frame, cv2.COLOR_BGR2RGB),
                        known_face_locations=face_locations
                    )
                    
                    for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):
                        # è¨ˆç®—è·é›¢
                        face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)
                        
                        if len(face_distances) > 0:
                            min_distance = min(face_distances)
                            is_friend = min_distance < CONFIDENCE_THRESHOLD
                            
                            if is_friend:
                                friend_found_this_frame = True
                                
                                # è¨ˆç®—è‡‰éƒ¨ä¸­å¿ƒè·é›¢
                                face_center = ((left + right) // 2, (top + bottom) // 2)
                                frame_center = (frame.shape[1] // 2, frame.shape[0] // 2)
                                distance = np.sqrt((face_center[0] - frame_center[0]) ** 2 + 
                                                 (face_center[1] - frame_center[1]) ** 2)
                                
                                if distance < TRIGGER_DISTANCE and not video_player.is_playing:
                                    video_player.play()
                                    friend_detected = True
                                    print(f"ğŸ‰ æª¢æ¸¬åˆ° {FRIEND_NAME}ï¼é–‹å§‹æ’­æ”¾å½±ç‰‡")
                                
                                if distance < TRIGGER_DISTANCE:
                                    friend_detected = True
                                    no_friend_frames = 0
                                
                                # ç¹ªè£½ç¶ è‰²æ¡†
                                cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)
                                info_text = f"{FRIEND_NAME} ({min_distance:.3f})"
                                frame = cv2_puttext_chinese(frame, info_text, (left, top - 30), 15, (0, 255, 0))
                            else:
                                # ç¹ªè£½ç´…è‰²æ¡†
                                cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)
                                info_text = f"Unknown ({min_distance:.3f})"
                                frame = cv2_puttext_chinese(frame, info_text, (left, top - 30), 15, (0, 0, 255))
                
                # è™•ç†æœ‹å‹é›¢é–‹é‚è¼¯
                if friend_detected:
                    if not friend_found_this_frame:
                        no_friend_frames += 1
                        if no_friend_frames >= NO_FRIEND_FRAMES_THRESHOLD:
                            friend_detected = False
                            no_friend_frames = 0
                            print(f"ğŸ‘‹ {FRIEND_NAME} å·²é›¢é–‹")
                    else:
                        no_friend_frames = 0

            # é¡¯ç¤ºç‹€æ…‹
            status = "æª¢æ¸¬ä¸­" if friend_detected else "ç›£æ§ä¸­"
            video_status = "æ’­æ”¾ä¸­" if video_player.is_playing else "å¾…æ©Ÿ"
            
            status_text = f"ç‹€æ…‹: {status} | å½±ç‰‡: {video_status}"
            frame = cv2_puttext_chinese(frame, status_text, (10, 30), 20, (255, 255, 255))
            
            # è¨ˆç®—FPS
            if frame_count % 30 == 0:
                fps = 30 / (current_time - fps_start_time + 0.001)
                fps_start_time = current_time
                fps_text = f"FPS: {int(fps)}"
                frame = cv2_puttext_chinese(frame, fps_text, (frame.shape[1] - 120, 30), 15, (255, 255, 255))

            cv2.imshow("Friend Detector", frame)
            
            # æª¢æŸ¥é€€å‡ºéµ
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break

    except KeyboardInterrupt:
        print("\nç¨‹å¼è¢«ç”¨æˆ¶ä¸­æ–·")
    except Exception as e:
        print(f"ç¨‹å¼åŸ·è¡ŒéŒ¯èª¤: {e}")
    finally:
        # æ¸…ç†è³‡æº
        print("æ­£åœ¨æ¸…ç†è³‡æº...")
        if video_player.is_playing:
            video_player.stop()
        cap.release()
        cv2.destroyAllWindows()
        print("ç¨‹å¼å·²å®‰å…¨é—œé–‰")

if __name__ == "__main__":
    main()